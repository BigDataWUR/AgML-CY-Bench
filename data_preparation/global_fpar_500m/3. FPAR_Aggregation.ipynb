{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Aggregating FPAR Data\n",
    "\n",
    "After successfully downloading and clipping FPAR data to your areas of interest, the next step is aggregating this data. This Jupyter notebook is designed to guide you through the aggregation of FPAR data, a process critical for summarizing and analyzing the data across various spatial and temporal dimensions.\n",
    "\n",
    "In this notebook, you will Aggregate FPAR data spatially and temporally to suit your research needs and save it as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIZP4uBqR9Np"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import rioxarray\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBBt8vK7SA4M"
   },
   "outputs": [],
   "source": [
    "# Define the shapefile and crop mask\n",
    "shapefile_path = ''\n",
    "shape_file = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Define the path of Crop Mask\n",
    "crop_mask_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIGdEpHpVwB_"
   },
   "outputs": [],
   "source": [
    "# function to extract the date from each file's name\n",
    "def extract_date_from_filename(filename):\n",
    "    pattern = r'\\d{8}'\n",
    "    match = re.search(pattern, filename)\n",
    "    date_str = match.group()\n",
    "    return date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTCLRtbiawwN"
   },
   "outputs": [],
   "source": [
    "# define the path of folders that contain the clipped data\n",
    "folder_path = \"\"\n",
    "file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.tif')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store results\n",
    "columns = ['date', 'LEVL_CODE', 'NUTS_ID', 'CNTR_CODE', 'MOUNT_TYPE', 'URBN_TYPE', 'COAST_TYPE', 'fpar']\n",
    "df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** If there addition information you need in the shape file you can modify the columns varialbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "##### Load crop mask and loop through each admin level in shapefile####\n",
    "#######################################################################\n",
    "\n",
    "with rasterio.open(crop_mask) as mask_src:\n",
    "    \n",
    "    # NOTE: You can slice the data path based on your processing power.\n",
    "    for raster in tqdm(file_paths, desc=\"Processing rasters\", unit=\"raster\"):\n",
    "\n",
    "        # Extract the date from the filename\n",
    "        file_name = os.path.basename(raster)\n",
    "        date_str = int(file_name[-12:-4])  # Extract the date part\n",
    "        \n",
    "        # Open the raster file\n",
    "        with rasterio.open(raster) as src:\n",
    "            \n",
    "            # Loop through each row in the shapefile\n",
    "            for _, row in shape_file.iterrows():\n",
    "                \n",
    "                # Clip the raster with the current geometry\n",
    "                geom = row.geometry\n",
    "                out_image, out_transform = mask(src, [geom], crop=True)\n",
    "\n",
    "                # Read the raster values and update them to nan where specified values are present\n",
    "                # 255 254 251 values not processed in FPAR data\n",
    "                invalid_values = [255, 254, 251]\n",
    "                out_image = np.where(np.isin(out_image, invalid_values), np.nan, out_image)\n",
    "\n",
    "                # Clip the mask with the current geometry\n",
    "                mask_image, _ = mask(mask_src, [geom], crop=True)\n",
    "\n",
    "                # Read the mask values and update them to nan where specified values are present\n",
    "                mask_image = np.where(np.isin(mask_image, invalid_values), np.nan, mask_image)\n",
    "\n",
    "                # Calculate the weighted mean\n",
    "                weighted_mean = np.nansum(out_image * mask_image) / np.nansum(mask_image)\n",
    "\n",
    "\n",
    "##################################################\n",
    "### Edit this part according to your shapefile####\n",
    "##################################################\n",
    "                \n",
    "                # Extract information of each admin1 from shapefile\n",
    "                LEVL_CODE = row['LEVL_CODE']\n",
    "                NUTS_ID = row['NUTS_ID']\n",
    "                CNTR_CODE = row['CNTR_CODE']\n",
    "                MOUNT_TYPE = row['MOUNT_TYPE']\n",
    "                URBN_TYPE = row['URBN_TYPE']\n",
    "                COAST_TYPE = row['COAST_TYPE']\n",
    "\n",
    "                # Append the weighted mean to the list\n",
    "                new_row = pd.DataFrame([{\n",
    "                    'date': date_str,\n",
    "                    'LEVL_CODE': LEVL_CODE,\n",
    "                    'NUTS_ID': NUTS_ID,\n",
    "                    'CNTR_CODE': CNTR_CODE,\n",
    "                    'MOUNT_TYPE': MOUNT_TYPE,\n",
    "                    'URBN_TYPE': URBN_TYPE,\n",
    "                    'COAST_TYPE': COAST_TYPE,\n",
    "                    'fpar': weighted_mean\n",
    "                }])\n",
    "\n",
    "                df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "df.to_csv('drive/MyDrive/AgML/FPAR/FPAR_CSV/FPAR_Wheat_Winter_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARvR94P2fa6K"
   },
   "outputs": [],
   "source": [
    "df.to_csv('', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
