{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "EqQy0RsXkx_1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracts and returns a list of .tif file URLs from a given webpage.\n",
        "def get_fpar_urls(url):\n",
        "  response = requests.get(url)\n",
        "  content = response.content\n",
        "  soup = BeautifulSoup(content, \"lxml\")\n",
        "  links = soup.find_all(\"a\")\n",
        "  tif_urls = [link.get(\"href\") for link in links if link.get(\"href\") and link.get(\"href\").endswith(\".tif\")]\n",
        "  return tif_urls"
      ],
      "metadata": {
        "id": "3uzQ_Hlok6G7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to filter the list of URLs based on the start and end dates\n",
        "def filter_urls_by_date(urls, start_date, end_date=None):\n",
        "    start_datetime = datetime.strptime(start_date, '%Y%m%d')\n",
        "    end_datetime = datetime.strptime(end_date, '%Y%m%d') if end_date else start_datetime\n",
        "    filtered_urls = [url for url in urls if start_datetime <= datetime.strptime(url[5:13], '%Y%m%d') <= end_datetime]\n",
        "    return filtered_urls"
      ],
      "metadata": {
        "id": "vibe78Rzh6Ha"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the URL of the FPAR data\n",
        "url = \"https://agricultural-production-hotspots.ec.europa.eu/data/indicators_fpar/fpar/\"\n",
        "\n",
        "# Get available FPAR Data\n",
        "tif_urls = get_fpar_urls(url)\n",
        "\n",
        "# Print the list of URLs\n",
        "print(\"FPAR URLs:\", tif_urls)"
      ],
      "metadata": {
        "id": "lzP8v5khk8Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the start and end date\n",
        "start_date = '20000521' # YYYYMMDD\n",
        "end_date = '2000801' # YYYYMMDD\n",
        "\n",
        "# Filter the URLs based on the start and end dates\n",
        "filtered_urls = filter_urls_by_date(tif_urls, start_date, end_date)\n",
        "filtered_urls"
      ],
      "metadata": {
        "id": "xrJEV58diQX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPcVGEdJktXf"
      },
      "outputs": [],
      "source": [
        "download_path = 'AgML/FPAR' # Specify the path where you want to save the downloaded files\n",
        "\n",
        "# Loop through the list of tif URLs\n",
        "for tif in filtered_urls:\n",
        "    # Build the URL to download\n",
        "    download_fpar = url + tif\n",
        "\n",
        "    # Extract the filename from the URL\n",
        "    filename = os.path.join(download_path, os.path.basename(download_fpar))\n",
        "\n",
        "    # Download the tif using wget and save it to the specified path\n",
        "    !wget {download_fpar} -P {download_path}\n",
        "\n",
        "    print(f\"Downloaded {filename}\")"
      ]
    }
  ]
}