{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add parent directory to path so we can import project files in notebook\n",
    "current_dir = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "lib_path = os.path.join(current_dir, \"..\")\n",
    "sys.path.append(lib_path)\n",
    "\n",
    "from runs.validate_model import validate_single_model\n",
    "from models.nn_models import ExampleLSTM\n",
    "from util.data import generate_settings, update_settings\n",
    "\n",
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set random seed for reproducibility for random, numpy, and torch\n",
    "seed = 16\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model_name_base = \"ExampleLSTM_test\"\n",
    "model_constructor = ExampleLSTM\n",
    "base_args = {\n",
    "    \"init\": {\n",
    "        \"n_ts_features\": 9,\n",
    "        \"n_static_features\": 1,\n",
    "        \"hidden_size\": 32,\n",
    "        \"num_layers\": 1,\n",
    "    },\n",
    "\n",
    "    \"fit\": {\n",
    "        'batch_size': 16,\n",
    "        'num_epochs': 150,\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        'optim_fn': torch.optim.Adam,\n",
    "        'optim_kwargs': {\"lr\": 0.0001, 'weight_decay': 0.00001},\n",
    "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
    "        'scheduler_kwargs': {\"step_size\": 1, \"gamma\": 1},\n",
    "        'val_fraction': 0.1,\n",
    "        'val_split_by_year': True,\n",
    "        'seed': 16,\n",
    "        'do_early_stopping': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "run_name_base = \"example_hparam_run\"\n",
    "\n",
    "# Define hyperparameters to search over and their values\n",
    "param_space = {\n",
    "    \"init.hidden_size\": [16, 32, 64],\n",
    "    \"init.num_layers\": [1, 2],\n",
    "    \"fit.optim_kwargs.lr\": [0.00001, 0.0001],\n",
    "    \"fit.optim_kwargs.weight_decay\": [0.00001],\n",
    "}\n",
    "\n",
    "\n",
    "settings = generate_settings(param_space, base_args)\n",
    "print(f\"Generated {len(settings)} settings to run.\")\n",
    "\n",
    "# Create base folder for run_name\n",
    "Path(f\"../output/runs/{run_name_base}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Shuffle settings\n",
    "random.shuffle(settings)\n",
    "\n",
    "# Run the hyperparameter search   \n",
    "for i, setting in enumerate(settings):\n",
    "\n",
    "    run_kwargs = update_settings(setting, base_args)\n",
    "\n",
    "    print(f\"Running {run_name_base} {i} with settings:\")\n",
    "    print(run_kwargs)\n",
    "\n",
    "    result_df = validate_single_model(\n",
    "        run_name_base + '_' + str(i),\n",
    "        model_name_base + '_' + str(i),\n",
    "        model_constructor,\n",
    "        run_kwargs['init'],\n",
    "        run_kwargs['fit'],\n",
    "        dataset_name = \"test_maize_us\",\n",
    "        test_years_to_leave_out=[2000],\n",
    "    )\n",
    "\n",
    "    # Save the results\n",
    "    result_df.to_csv(f\"../output/runs/{run_name_base}/{run_name_base}_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from runs.run_benchmark import run_benchmark\n",
    "from util.data import flatten_nested_dict, update_settings, unflatten_nested_dict\n",
    "\n",
    "#run_name_base = \"example_hparam_run\"\n",
    "\n",
    "# Loop over results and print the best one\n",
    "best_result = None\n",
    "best_result_idx = None\n",
    "result_list = []\n",
    "setting_list = []\n",
    "for i, path in enumerate(Path(f\"../output/runs/{run_name_base}\").rglob(\"*.csv\")):\n",
    "    result_df = pd.read_csv(path)\n",
    "\n",
    "    \n",
    "    init_setting = result_df.iloc[0, 1]\n",
    "    fit_setting = result_df.iloc[1, 1]\n",
    "\n",
    "    # eval, but remove strings between < and > first\n",
    "\n",
    "    init_setting = eval(re.sub(r'<.*?>', '', init_setting))\n",
    "    fit_setting = eval(re.sub(r'<.*?>', \"''\", fit_setting))\n",
    "\n",
    "    # Combine into one dict using flatten_nested_dict\n",
    "    all_setting = flatten_nested_dict({\"init\": init_setting, \"fit\": fit_setting})\n",
    "\n",
    "    if fit_setting['do_early_stopping']:\n",
    "        val_loss = result_df.iloc[6, 1]\n",
    "    else:\n",
    "        val_loss = result_df.iloc[3, 1]\n",
    "    print(f\"Setting {i}: {val_loss}\")\n",
    "    result_list.append(val_loss)\n",
    "    setting_list.append(all_setting)\n",
    "    if best_result is None or val_loss < best_result:\n",
    "        best_result = val_loss\n",
    "        best_result_idx = i\n",
    "\n",
    "print(f\"Best result: {best_result} at index {best_result_idx}\")\n",
    "print(f\"{pd.DataFrame(setting_list[best_result_idx], index=['Best settings:']).T}\")\n",
    "\n",
    "\n",
    "# Save best results to file\n",
    "with open(f\"../output/runs/{run_name_base}/best_settings_result.txt\", \"w\") as f:\n",
    "    f.write(f\"Best result: {best_result} at index {best_result_idx}\\n\")\n",
    "\n",
    "# Save best settings dict to file with pickle\n",
    "import pickle\n",
    "settings_to_save = setting_list[best_result_idx]\n",
    "with open(f\"../output/runs/{run_name_base}/best_settings_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(settings_to_save, f)\n",
    "\n",
    "# Unwrap settings from list of dicts to dict of lists\n",
    "# flatten settings\n",
    "new_settings = {}\n",
    "for i, setting in enumerate(setting_list):\n",
    "    \n",
    "    flattened_setting = flatten_nested_dict(setting)\n",
    "    for k, v in flattened_setting.items():\n",
    "        # Take only final part of key, after last dot\n",
    "        k = k.split('.')[-1]\n",
    "        if k not in new_settings:\n",
    "            new_settings[k] = []\n",
    "        # Take only final part of key\n",
    "        new_settings[k].append(v)\n",
    "\n",
    "# Create dataframe from settings\n",
    "df = pd.DataFrame(new_settings)\n",
    "\n",
    "\n",
    "# Add val_loss column\n",
    "df['val_loss'] = result_list\n",
    "df['val_loss'] = df['val_loss'].astype(float)\n",
    "\n",
    "# Filter out columns where all values are the same\n",
    "df = df.loc[:, df.nunique() != 1]\n",
    "\n",
    "# Make box plots of val loss for hidden_size\tnum_layers\tlr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# For each hyperparameter that is not the same for all settings, plot a scatter plot of val_loss vs. that hyperparameter\n",
    "# Plot them side by side\n",
    "unique_columns = [col for col in df.columns if df[col].nunique() > 1 and df[col].name != 'val_loss']\n",
    "num_cols = len(unique_columns)\n",
    "print(unique_columns)\n",
    "fig, axs = plt.subplots(1, num_cols, figsize=(5 * num_cols, 5))\n",
    "\n",
    "col_idx = 0\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() > 1 and df[col].name != 'val_loss':\n",
    "        sns.scatterplot(x=col, y='val_loss', data=df, ax=axs[col_idx])\n",
    "        col_idx += 1\n",
    "plt.show()\n",
    "\n",
    "# Same for box plots\n",
    "num_cols = len([col for col in df.columns if df[col].nunique() > 1 and df[col].name != 'val_loss'])\n",
    "fig, axs = plt.subplots(1, num_cols, figsize=(5 * num_cols, 5))\n",
    "\n",
    "col_idx = 0\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() > 1 and df[col].name != 'val_loss':\n",
    "        sns.boxplot(x=col, y='val_loss', data=df, ax=axs[col_idx])\n",
    "        col_idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best settings dict from file with pickle\n",
    "import pickle\n",
    "with open(f\"../output/runs/{run_name_base}/best_settings_dict.pkl\", \"rb\") as f:\n",
    "    best_settings = pickle.load(f)\n",
    "\n",
    "\n",
    "# Assert that the best settings are the same as the best settings found if settings exist\n",
    "if best_result_idx is not None: \n",
    "    assert best_settings == settings[best_result_idx]\n",
    "\n",
    "\n",
    "# Run the full benchmark for the best settings\n",
    "run_kwargs = update_settings(best_settings, base_args)\n",
    "result_df = run_benchmark(\n",
    "    run_name_base + '_best',\n",
    "    model_name_base + '_best',\n",
    "    model_constructor,\n",
    "    run_kwargs['init'],\n",
    "    run_kwargs['fit'],\n",
    ")\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the evaluation results\n",
    "from runs.run_benchmark import _compute_evaluation_results\n",
    "_compute_evaluation_results(run_name_base + '_best')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gxemaize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
